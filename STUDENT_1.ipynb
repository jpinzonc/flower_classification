{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STUDENT_1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oSPWHPf_4_Mt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/alexandrebvd/pytorch-challenge/blob/master/Image%20Classifier%20Project_Resnet152_newflowers.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "9Ta1HEGE4_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import json\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2d46ebrVftXz",
        "outputId": "2f198459-a4da-4343-8036-0bd805d6ed14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "####JP\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install Pillow==5.3.0\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "#import torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==5.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.9MB/s \n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed Pillow-5.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m  HTTP error 403 while getting http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31m  Could not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n",
            "\u001b[31mCould not install requirement torch==0.4.1 from http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl because of HTTP error 403 Client Error: Forbidden for url: http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl for URL http://download.pytorch.org/whl/cu100/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6JW129ATOlEB",
        "outputId": "2184d224-97b1-4bac-d12c-a549b6950846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "####JP\n",
        "# If version is not 5.3.0, re install and restart\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "# If it shows version three reset runtime and start running from next cell"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sTNL6HexfoB8",
        "outputId": "a0ad2930-49a1-4667-ea7e-7d1fc9d2ea41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms, models, utils\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Necesary to unzip the data file\n",
        "import zipfile\n",
        "# If version is not 5.3.0, re install and restart\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZeSnfqNwVPSX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#zipfile.ZipFile('flower_data_short.zip').extractall('flower_data') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj0zbfGPPJJT",
        "outputId": "52f4a602-e21a-4ab5-df94-8248c8a5f99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IAZP2en2PYD_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('gdrive/My Drive/01_GitHub/pytorch_challenge')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ovTAhVk4_Nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ]
    },
    {
      "metadata": {
        "id": "WlIJr2Sl4_Nm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'flower_data' #Balanced dataset through oversampling\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F05WAdSl4_Nq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "\n",
        "# how many samples per batch to load\n",
        "batch_size = 16\n",
        "number_classes = 102\n",
        "n_workers = 4\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224, scale=(0.25, 1.0)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
        "                                       #transforms.RandomGrayscale(p=0.2),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform = train_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform = validation_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = n_workers)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, num_workers = n_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loBtXRtZ4_Nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Labels"
      ]
    },
    {
      "metadata": {
        "id": "gUxxO_1F4_Nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4tOj8e5R4_Ny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build Classifiers"
      ]
    },
    {
      "metadata": {
        "id": "3AhcPzyn4_N0",
        "colab_type": "code",
        "outputId": "0ad58340-004c-4421-ca2d-c9da5063958f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.resnet152(pretrained=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.torch/models/resnet152-b121ed2d.pth\n",
            "241530880it [00:02, 89227292.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ioM3KxPB4_N-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 1600),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(0.3),\n",
        "                         nn.Linear(1600, 102),\n",
        "                         nn.LogSoftmax(dim=1))\n",
        "\n",
        "model.class_to_idx = train_dataset.class_to_idx\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Only train the classifier parameters; previous parameters are frozen\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.0002)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5, last_epoch=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxhXS9XV4_OB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use GPU if it's available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_lSmajB4_OF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 25\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if device.type=='cuda':\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        class_correct = list(0. for i in range(number_classes))\n",
        "        class_total = list(0. for i in range(number_classes))\n",
        "\n",
        "        for data, target in validation_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device.type=='cuda':\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "\n",
        "            # convert output probabilities to predicted class\n",
        "            _, pred = torch.max(output, 1)\n",
        "            # compare predictions to true label\n",
        "            correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "            # calculate test accuracy for each object class\n",
        "            for i in range(int(output.size(0))):\n",
        "                label = target.data[i]\n",
        "                class_correct[label] += correct[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "        #Organizing the list to match the folders in order\n",
        "        class_correct_ordered = list(0. for i in range(len(class_correct)))\n",
        "        class_total_ordered = list(0. for i in range(len(class_total)))\n",
        "        for key, value in model.class_to_idx.items():\n",
        "            class_correct_ordered[int(key)-1] = class_correct[value]\n",
        "            class_total_ordered[int(key)-1] = class_total[value]\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(train_loader.dataset)\n",
        "        valid_loss = valid_loss/len(validation_loader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "\n",
        "    for i in range(number_classes):\n",
        "        if class_total_ordered[i] > 0:\n",
        "            print('Validation Accuracy of class %3s (%25s): %0.2f%% (%2d/%2d)' % (\n",
        "                str(i+1), cat_to_name[str(i+1)], 100 * class_correct_ordered[i] / class_total_ordered[i],\n",
        "                np.sum(class_correct_ordered[i]), np.sum(class_total_ordered[i])))\n",
        "        else:\n",
        "            print('Validation Accuracy of class %3s (%25s): N/A (no training examples)' % (str(i+1), cat_to_name[str(i+1)]))\n",
        "            \n",
        "    valid_accuracy = 100. * np.sum(class_correct_ordered) / np.sum(class_total_ordered)\n",
        "    print('\\nValidation Accuracy (Overall): %0.2f%% (%2d/%2d)\\n' % (\n",
        "        valid_accuracy, np.sum(class_correct_ordered), np.sum(class_total_ordered)))\n",
        "    \n",
        "\n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...\\n\\n'.format(\n",
        "        valid_loss_min, valid_loss))\n",
        "        \n",
        "        checkpoint = {'model_state_dict':model.state_dict(),\n",
        "             #'optimizer_state_dict':optimizer.state_dict(),\n",
        "             'classifier_model':model.fc,\n",
        "             'epochs':n_epochs,\n",
        "             'best_accuracy':valid_accuracy,\n",
        "             'model_class_idx':model.class_to_idx}\n",
        "        torch.save(checkpoint, 'model_resnet152_pytorch_challenge.pt')\n",
        "        \n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7WfrvGN4_OO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Save the checkpoint (Already done above)\n",
        "'''checkpoint = {'model_state_dict':model.state_dict(),\n",
        "             'optimizer_state_dict':optimizer.state_dict(),\n",
        "             'classifier_model':model.fc,\n",
        "             'epochs':n_epochs,\n",
        "             'best accuracy':test_accuracy,\n",
        "             'model_class_idx':model.class_to_idx}\n",
        "    torch.save(checkpoint, 'model_pytorch_challenge.pt')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eqSapCUm4_OR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
        "\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    \n",
        "    model = models.resnet152(pretrained=True)\n",
        "    \n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.fc = checkpoint['classifier_model']\n",
        "    model.class_to_idx = checkpoint['model_class_idx']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    #optimizer = optim.Adam(model.fc.parameters())\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    \n",
        "    epochs = checkpoint['epochs']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgxC4tyq4_OY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    # TODO: Process a PIL image for use in a PyTorch model\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    preprocess = transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     normalize])\n",
        "    im = Image.open(image)\n",
        "    im_tensor = preprocess(im)\n",
        "\n",
        "    return im, im_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9CY9spp4_Oi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pil,tensor = process_image('random flower pictures/image_04927.jpg')\n",
        "tensor.shape\n",
        "pil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y8LT8oVp4_Oo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HotqUpa04_Os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "imshow(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_1xmRRUI4_Ov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(image_path, model, topk=5):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # TODO: Implement the code to predict the class from an image file\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    model.cpu()\n",
        "    \n",
        "    # load image as torch.Tensor\n",
        "    _, image = process_image(image_path)\n",
        "\n",
        "    # Un-squeeze returns a new tensor with a dimension of size one\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    # Disabling gradient calculation\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        top_prob, top_labels = torch.topk(output, topk)\n",
        "\n",
        "        # Calculate the exponential\n",
        "        top_prob = top_prob.exp()\n",
        "\n",
        "    class_to_idx_inv = {model.class_to_idx[key]: int(key) for key, value in model.class_to_idx.items()}\n",
        "    mapped_classes = []\n",
        "\n",
        "    for label in top_labels.numpy()[0]:\n",
        "        mapped_classes.append(class_to_idx_inv[label])\n",
        "\n",
        "    return top_prob.numpy()[0], mapped_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkyrZOo64_Ox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Display an image along with the top 5 classes after loading the model\n",
        "model_loaded = load_checkpoint('model_resnet152_pytorch_challenge.pt')\n",
        "\n",
        "img_cat = {'random flower pictures/image_04903.jpg':cat_to_name['20'],\n",
        "           'random flower pictures/image_04927.jpg':cat_to_name['20'],\n",
        "           'random flower pictures/image_07925.jpg':cat_to_name['100'],\n",
        "           'random flower pictures/image_08067.jpg':cat_to_name['31'],\n",
        "           'random flower pictures/image_06905.jpg':cat_to_name['31'],\n",
        "           'random flower pictures/image_07075.jpg':cat_to_name['67']}\n",
        "\n",
        "for img, cat in img_cat.items():\n",
        "    top_prob, top_classes = predict(img, model_loaded)\n",
        "\n",
        "    label = top_classes[0]\n",
        "\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    sp_img = plt.subplot2grid((15,9), (0,0), colspan=9, rowspan=9)\n",
        "    sp_prd = plt.subplot2grid((15,9), (9,2), colspan=5, rowspan=5)\n",
        "\n",
        "    image = Image.open(img)\n",
        "    sp_img.axis('off')\n",
        "    sp_img.set_title(f'{cat}')\n",
        "    sp_img.imshow(image)\n",
        "\n",
        "    labels = []\n",
        "    for class_idx in top_classes:\n",
        "        labels.append(cat_to_name[str(class_idx)] + ' (class ' + str(class_idx) + ')')\n",
        "\n",
        "    yp = np.arange(5)\n",
        "    sp_prd.set_yticks(yp)\n",
        "    sp_prd.set_yticklabels(labels)\n",
        "    sp_prd.set_xlabel('Probability')\n",
        "    sp_prd.invert_yaxis()\n",
        "    sp_prd.barh(yp, top_prob, xerr=0, align='center', color='blue')\n",
        "\n",
        "    plt.show()\n",
        "    print(f'Correct prediction: {cat == cat_to_name[str(label)]}')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}